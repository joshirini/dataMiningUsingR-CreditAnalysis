---
title: "Credit_NPV1_markdown"
author: "Rini Joshi"
date: "3/8/2017"
output: word_document
---


```{r create dependent variable}
#create a binay dependent variable using NPV column 
knn_credit_df <- read.csv("credit3.csv")
knn_npv_class <- as.factor(ifelse((knn_credit_df$NPV) > 0, 1, 0))
knn_credit_df <- cbind(knn_credit_df,knn_npv_class)
```

```{r create dummy variable}

#create dummy variables for categorical columns
library("dummies")
knn_new_dummy_df <- dummy.data.frame(knn_credit_df, sep=".", names=c("CHK_ACCT","SAV_ACCT","HISTORY","JOB","TYPE"))

#assign all irrelevant columns as NULL
knn_new_dummy_df$OBS.<- NULL
knn_new_dummy_df$NPV <- NULL
knn_new_dummy_df$CREDIT_EXTENDED <- NULL
knn_new_dummy_df$AMOUNT_REQUESTED <- as.numeric(knn_new_dummy_df$AMOUNT_REQUESTED)

#set the seed
set.seed(12345)

#splitting the data into training and testing with ratio of 7:3
knn_train <- sample(nrow(knn_new_dummy_df),0.7*nrow(knn_new_dummy_df))
knn_credit_df_train<-knn_new_dummy_df[knn_train,]
knn_credit_df_validation<-knn_new_dummy_df[-knn_train,]
```

```{r normalize and model data}
#normalization of all the data; basically to normalize numeric data. The rest of the data is either binary or NULL.
normalize <- function(x) {
    return ((as.numeric(x) - min(as.numeric(x))) / (max(as.numeric(x)) - min(as.numeric(x))))
}

#apply normalization
norm_train_df <- as.data.frame(lapply(knn_credit_df_train, normalize))
norm_validation_df <- as.data.frame(lapply(knn_credit_df_validation, normalize))

norm_train_df_output <- as.vector(norm_train_df[,41])
norm_validation_df_output <- as.vector(norm_validation_df[,41])

norm_train_df_input <- norm_train_df
norm_validation_df_input <- norm_validation_df

#convert the original NPV colum to NULL as it has already been categorized to npv_class
norm_train_df_input$knn_npv_class <- NULL
norm_validation_df_input$knn_npv_class <- NULL

#convert the input training data as matrix
norm_train_df_input <- as.matrix(norm_train_df_input)
norm_validation_df_input <- as.matrix(norm_validation_df_input)

#set.seed(12345)
library("class")

#create error matrix to hold the error values
error_rate_train <- rep(0,15)
error_rate_validation <- rep(0,15)
Error1 <- rep(0,15)
Error0 <- rep(0,15)
library("ROCR")

#run Knn classifier with k=1 to 15
for (i in 1:15){
  knn_prediction_train <- knn(norm_train_df_input,norm_train_df_input,norm_train_df_output,k=i)
  knn_prediction_validation <- knn(norm_train_df_input,norm_validation_df_input,norm_train_df_output,k=i)
  
  if(i==13) {
    knn_rocr_validation_pred <- prediction(as.numeric(knn_prediction_validation),as.numeric(norm_validation_df_output))
  }
  #confusion matrix
  knn_confusion_matrix_train <-table(knn_prediction_train,norm_train_df_output)
  knn_confusion_matrix_validate <-table(knn_prediction_validation,norm_validation_df_output)
  
  #training error rate
  error_rate_train[i] <- (knn_confusion_matrix_train[1,2]+knn_confusion_matrix_train[2,1])/sum(knn_confusion_matrix_train)
  error_rate_validation[i] <- (knn_confusion_matrix_validate[1,2]+knn_confusion_matrix_validate[2,1])/sum(knn_confusion_matrix_validate) 
  Error1[i] <- knn_confusion_matrix_validate[1,2]/(knn_confusion_matrix_validate[1,2]+knn_confusion_matrix_validate[2,2])
  Error0[i] <- knn_confusion_matrix_validate[2,1]/(knn_confusion_matrix_validate[2,1]+knn_confusion_matrix_validate[1,1])

}
 

```

```{r Plotting error rate versus k}
plot(c(1,15),c(0,0.4),type ="n",xlab = "k",ylab = "Errror Rate")
lines(error_rate_train,col="red")
lines(error_rate_validation,col="blue")
legend(9,0.1,c("Training","Validation"),lty=c(1,1),col = c("red","blue"))

#finding k with the minimum error
min_k <- which.min(error_rate_validation)
min_k

```

```{r min error rate on test data}
#error rate for 2 classes on validation data/test data
Error1[min_k]

Error0[min_k]
```

```{r experimentation with seed value}

#creating the above results with varying seed from 1 to 10.

min_seed_k <- rep(0,10)
for(seed in 1:10) {
set.seed(seed)
library("class")
knn2_error_rate_train <- rep(0,15)
knn2_error_rate_validation <- rep(0,15)


for (i in 1:15){
  knn2_prediction_train <- knn(norm_train_df_input,norm_train_df_input,norm_train_df_output,k=i)
  knn2_prediction_validation <- knn(norm_train_df_input,norm_validation_df_input,norm_train_df_output,k=i)
 
  #confusion matrix
  knn2_confusion_matrix_train <-table(knn2_prediction_train,norm_train_df_output)
  knn2_confusion_matrix_validate <-table(knn2_prediction_validation,norm_validation_df_output)
  
  #training error rate
  knn2_error_rate_train[i] <- (knn2_confusion_matrix_train[1,2]+knn2_confusion_matrix_train[2,1])/sum(knn2_confusion_matrix_train)
  knn2_error_rate_validation[i] <- (knn2_confusion_matrix_validate[1,2]+knn2_confusion_matrix_validate[2,1])/sum(knn2_confusion_matrix_validate) 
}

min_seed_k[seed] <- which.min(knn2_error_rate_validation)
}

min_seed_k
```


```{r Naive Bayes}
#Naive Bayes

#Load the data
nb_credit_df <- read.csv("credit3.csv")

#classify original NPV column as 1 or 0
nb_npv_class <- as.factor(ifelse(nb_credit_df$NPV > 0, 1, 0))
nb_credit_df <- cbind(nb_credit_df,nb_npv_class)

#convert variables into factors
nb_credit_df$OBS. <- NULL
nb_credit_df$CREDIT_EXTENDED <- NULL
nb_credit_df$NPV <- NULL
nb_credit_df$CHK_ACCT <- as.factor(nb_credit_df$CHK_ACCT)
nb_credit_df$SAV_ACCT <- as.factor(nb_credit_df$SAV_ACCT)
nb_credit_df$HISTORY <- as.factor(nb_credit_df$HISTORY)
nb_credit_df$JOB <- as.factor(nb_credit_df$JOB)
nb_credit_df$TYPE <- as.factor(nb_credit_df$TYPE)

#reset seed to 12345
set.seed(12345)

#divide the data
nb_train <- sample(nrow(nb_credit_df),0.7*nrow(nb_credit_df))
nb_credit_df_train<-nb_credit_df[nb_train,]
nb_credit_df_validation<-nb_credit_df[-nb_train,]

```
```{r run Naive bayes model}

library("e1071")
nb_model <- naiveBayes(nb_npv_class~., data=nb_credit_df_train)

nb_model 
nb_prediction <- predict(nb_model, nb_credit_df_validation[,-21])

#confusion matrix
table(nb_credit_df_validation$nb_npv_class,nb_prediction,dnn=list('actual','predicted'))

```

```{r Predicitng NPV for a given account with following properties}
fit_newdata <- data.frame(AGE=27,CHK_ACCT=1,SAV_ACCT=4,NUM_CREDITS=1,DURATION=12,HISTORY=1,PRESENT_RESIDENT=1,EMPLOYMENT=1,JOB=2,NUM_DEPENDENTS=0,RENT=1,INSTALL_RATE=3,GUARANTOR=0,OTHER_INSTALL=0,OWN_RES=0,TELEPHONE=1,FOREIGN=0,REAL_ESTATE=0,TYPE=2,AMOUNT_REQUESTED=4500)

predict(nb_model,fit_newdata)

predict(nb_model,fit_newdata,type="raw")
```

```{r Logistic Regression}
#Logistic Regression

glm_credit_df <- read.csv("credit3.csv")
glm_npv_class <- ifelse((glm_credit_df$NPV) > 0, 1, 0)
glm_credit_df <- cbind(glm_credit_df,glm_npv_class)

#assign dummy variables
library("dummies")
glm_new_dummy_df <- dummy.data.frame(glm_credit_df, sep=".", names=c("CHK_ACCT","SAV_ACCT","HISTORY","JOB","TYPE"))


#assign all irrelevant columns as NULL
glm_new_dummy_df[,1]<- NULL
glm_new_dummy_df$NPV <- NULL
glm_new_dummy_df$CREDIT_EXTENDED <- NULL
glm_new_dummy_df$AMOUNT_REQUESTED <- as.numeric(glm_new_dummy_df$AMOUNT_REQUESTED)

#reset seed to 12345
set.seed(12345)

#divide the data
glm_train <- sample(nrow(glm_new_dummy_df),0.7*nrow(glm_new_dummy_df))
glm_credit_df_train<-glm_new_dummy_df[glm_train,]
glm_credit_df_validation<-glm_new_dummy_df[-glm_train,]


glm_df_fit <- glm(glm_npv_class ~.,data=glm_credit_df_train, family="binomial")
summary(glm_df_fit)

glm_validation_predict <- predict(glm_df_fit,glm_credit_df_validation, type="response")
glm_validation_roundoff <- ifelse(glm_validation_predict>0.5,1,0)

#confusion matrix
table(glm_credit_df_validation$glm_npv_class,glm_validation_roundoff,dnn=list('actual','predicted'))

```

```{r ROC curves}
#ROC curves for various models
#First do it for Logistic Regression, then Naive Bayes, and finally for KNN. Plot on one graph.
library("ROCR")
glm_rocr_validation_pred <- prediction(glm_validation_predict, glm_credit_df_validation$glm_npv_class)
glm_rocr_validation_perf <- performance(glm_rocr_validation_pred, "tpr", "fpr")

nb_rocr_validation_pred <- prediction(as.numeric(nb_prediction), as.numeric(nb_credit_df_validation$nb_npv_class))
nb_rocr_validation_perf <- performance(nb_rocr_validation_pred, "tpr", "fpr")

knn_rocr_validation_perf <- performance(knn_rocr_validation_pred, "tpr", "fpr")

plot(glm_rocr_validation_perf,type="l",col="red", main = "ROC curves")
plot(nb_rocr_validation_perf,type="l",col="blue", add=TRUE)
plot(knn_rocr_validation_perf,type="l",col="purple", add=TRUE)
abline(0,1,lty = 2, col="black", add="TRUE")

legend(0.4,0.5,c("Logistic","Naive Bayes","KNN"),lty = c(1.2,1.2),col = c("red","blue","purple"))


```



